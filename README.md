# BigData

# Задание
# Необходимо написать пайплайн с помощью фреймворка Luigi.

# Порядок действий
# Шаг 1
Скачать supplementary-файлы датасета GSE68849 из GEO → cтраница датасета. Архив называется GSE68849_RAW.tar.
Как вы можете увидеть, здесь стандартный endpoint, в который параметром подставляется название датасета.
В задаче на скачивание имя датасета должно быть параметром.
Хотя ссылку на скачивание можно захардкодить, более корректный подход — спарсить страницу и извлечь ссылку оттуда. 
Скачайте архив в заранее подготовленную папку. 
Скачивать можно с помощью библиотеки wget для Python.
Если нужно запустить какой-то Bash-код, используйте библиотеку subprocess.
# Шаг 2
После скачивания в папке появится tar-архив, содержимое которого — gzip-заархивированные файлы.
Нужно разархивировать общий архив, узнать, сколько в нем файлов и как они называются, создать под каждый файл папку и разархивировать его туда.
Текстовые файлы представляют собой набор из четырех tsv-таблиц, каждая из которых обозначена хедером. Хедеры начинаются с символа [. Для удобства каждую таблицу нужно сохранить в отдельный tsv-файл.
# Шаг 3
Таблица Probes содержит очень много колонок, часть из которых — большие текстовые поля. Помимо полного файла с этой таблицей, сохраните также урезанный файл.
Из него нужно убрать следующие колонки: Definition, Ontology_Component, Ontology_Process, Ontology_Function, Synonyms, Obsolete_Probe_Id, Probe_Sequence.
# Шаг 4
Изначальный текстовый файл можно удалить, убедившись, что все предыдущие этапы успешно выполнены.

# Запуск через консоль
python main.py FinalTask --dataset GSE68849 --folder ./output --local-scheduler
